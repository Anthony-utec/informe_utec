---
title: "PG2-Informe"
output:
  html_document:
    df_print: paged
    toc: TRUE
---
#  **COMPORTAMIENTO DIGITAL DE LOS ESTUDIANTES DE UTEC MATRICULADOS ES EL CICLO 2023 -1**   

##  **I. INTRODUCCIÓN** 
### __Relevancia__

Este estudio es relevante porque buscamos analizar el comportamiento digital de los estudiantes de UTEC en el ciclo 2023-1, un aspecto que ha cobrado mayor importancia en el contexto actual de educación a distancia a raíz de la pandemia del 2021, buscamos identificar las fortalezas y debilidades de las herramientas digitales así como su percepción sobre la calidad y fiabilidad de la información que encuentran en la web y su conocimiento y cumplimiento de las normas de propiedad intelectual. Estos aspectos son fundamentales para el desarrollo de competencias digitales que les permitan a los estudiantes aprovechar al máximo las oportunidades y recursos que ofrece el entorno digital para su formación académica y profesional

### __Objetivos__

##### - __Objetivo General__  

  - El estudio tiene como objetivo general analizar el comportamiento digital, de los estudiantes de UTEC en el ciclo 2023–1, en su proceso de estudio, su responsabilidad como consumidores digitales y su conocimiento y cumplimiento de las normas de propiedad intelectual, con el fin de identificar áreas de mejora y oportunidades de educación y sensibilización en estos temas.

##### - __Objetivos específicos__  

- **Objetivo específico 01**: Analizar la percepción de la efectividad y nivel de satisfacción de las herramientas digitales utilizadas por los estudiantes de UTEC en el ciclo 2023-1 para el estudio, incluyendo plataformas de aprendizaje en línea, aplicaciones de gestión del tiempo, aplicaciones para reuniones y herramientas de toma de notas.  
- **Objetivo específico 02**: Evaluar la percepción respecto a la cantidad de información de poca confiabilidad que se presenta en la web entre los estudiantes UTEC en el ciclo 2023-1, con el propósito de identificar la confianza de los estudiantes respecto a sus investigaciones y estrategias que utilizan para solucionar dicha problemática.
- **Objetivo específico 03**: Evaluar el nivel de conocimiento y cumplimiento de los estudiantes UTEC en el ciclo 2023-1 en relación a las normas y regulaciones de propiedad intelectual en el ambiente digital, con la finalidad de identificar el nivel de práctica responsable que conllevan los alumnos en el contexto de los derechos de autor. 
  
### __Contexto__
Para poder entender nuestro tema de estudio es necesario partir por qué tipo de herramientas digitales son las que utiliza la comunidad de estudiantes de UTEC, el nivel de confianza que tienen al utilizar estas herramientas y las acciones que toman para asegurarse de cumplir con las normas y regulaciones de propiedad intelectual que existen en sus trabajos académicos y actividades en línea.


 - **Librerías para la lectura**  
 Para realizar el trabajo usaremos diferentes librerías, instalaremos los paquetes que necesitamos y cargamos las librerías.
 
```{r}

library(readr)
library(plyr)
library(dplyr)

```


 - **Cargar base de datos**
```{r }

datos_filtrados1 <- read.csv("datos_filtrados1.csv")

datos_filtrados1


```


##  **II. ANÁLISIS DESCRIPTIVO**

#### __- Descriptores numéricos y gráficos de las variables del estudio__

Algunas librerías a utilizar:
```{r}

library(ggplot2)

```
#### __EDAD__  

```{r echo=FALSE}
library(ggplot2)
mode <- function(x) {
   return(as.numeric(names(which.max(table(x)))))
}

# Calcular porcentajes
total_datos <- length(datos_filtrados1$Edad)
porcentaje_frecuencia <- table(datos_filtrados1$Edad) / total_datos * 100

media <- mean(datos_filtrados1$Edad)
edadSort <- sort(datos_filtrados1$Edad)
mediana <- median(edadSort)
moda <- mode(datos_filtrados1$Edad)

titulo <- "Histograma de las edades de los alumnos"
subtitulo <- paste("Media =", round(media, 2), " Mediana =", mediana, " Moda =", moda)
ggplot(data = datos_filtrados1, mapping = aes(x = Edad)) +
  geom_histogram(aes(y = ..count.. / total_datos * 100), bins = 145) +
  ggtitle(titulo, subtitle = subtitulo) +
  xlab('Edades') + ylab('Porcentaje') +
  geom_vline(aes(xintercept = media, color = "media"), linetype = "dashed", size = 1) +
  geom_vline(aes(xintercept = mediana, color = "mediana"), linetype = "dashed", size = 1) +
  geom_vline(aes(xintercept = moda, color = "moda"), linetype = "dashed", size = 0.5)


```
```{r}
summary(datos_filtrados1$Edad)
```
##### - __Análisis__

- De acuerdo a los estudiantes encuestados se observa que las edades oscilan entre 18, 19 y 20 a simple vista.
- De acuerdo a los estudiantes encuestados se observa que la moda es 18, por lo que la mayoría de nuestros encuestados tienen esa edad.
- También se observa que la media es 19.5 y la mediana 19.

#### __TIEMPO MÁXIMO DE ESTUDIO DIGITAL__          

```{r echo=FALSE}
# Tiempo máximo de estudio digital vs Tiempo máximo de estudio tradicional

tmax_D <- datos_filtrados1$Tmax_estudio_digital
tmax_T <- datos_filtrados1$Tmax_estudio_tradicional


vn1 <- as.numeric(tmax_D)
vn2 <- as.numeric(tmax_T)

# Calcular porcentajes
porcentaje_tmax_D <- table(tmax_D) / length(tmax_D) * 100
# Gráfico de número de encuestados respecto al Tiempo máximo de estudio digital
barp_2 <- barplot(porcentaje_tmax_D,
          xlab = "Tiempo máximo de estudio digital (horas semanales)",
          ylab = "Porcentaje",
          main = "Porcentaje de encuestados respecto al Tiempo máximo de estudio digital",
          ylim = c(0, 20))


```

#### __TIEMPO MÁXIMO DE ESTUDIO DIGITAL__

```{r echo=FALSE}

boxplot(vn1,
        xlab = "Tiempo máximo de estudio digital",
        ylab = "Encuestados",
        main = "Encuestados respecto al Tiempo máximo de estudio digital",
        col= "red3") 

```

 
```{r}
summary(datos_filtrados1$Tmax_estudio_digital)
```
##### - __Análisis__  
- Variable numérica continua.

- Podemos observar que el número de encuestados que respondió 0 horas semanales de estudio digital es mínimo a comparación de los que si han respondido con horas de estudio existentes, es decir, la mayoría si utiliza la tecnología para estudiar.

- Podemos observar que la gran mayoría de estudiantes estudia 20 horas semanalmente de forma digital.

- El tiempo de estudio digital llega hasta un máximo de 72 horas semanales, podemos decir que una gran cantidad de encuestados estas muy familiarizados con la tecnología por la cantidad de horas que invierten.      
- Cuando calculamos el rango intercuartil, obtenemos que es Q3-q1 = 15, entonces obtenemos que hay una diferencia de 15 horas semanales por estudio máximo digital, es decir, esto muestra el rango que hay de horas semanales de estudio máximo digital entre el tercer cuartil y el primer cuartil de los encuestados.

- En este caso, indica que el 50% central de los encuestados tiene como tiempo maximo de estudio digital que varían en un rango de 15 horas semanales.

#### __TIEMPO MÁXIMO DE ESTUDIO TRADICIONAL__   

```{r echo=FALSE}

porcentaje_tmax_T <- table(tmax_T) / length(tmax_T) * 100

barplot(porcentaje_tmax_T,
        xlab = "Tiempo máximo de estudio tradicional (horas semanales)",
        ylab = "Porcentaje",
        main = "Porcentaje de encuestados respecto al Tiempo máximo de estudio tradicional",
        ylim = c(0, 20))

```
 
 
```{r echo=FALSE}
boxplot(vn2,
        xlab = "Tiempo máximo de estudio tradicional",
        ylab = "Encuestados",
        main = "Encuestados respecto al Tiempo máximo de estudio tradicional",
        col= "skyblue3") 
```
 
   
   
```{r}
summary(datos_filtrados1$Tmax_estudio_tradicional)
```

##### - __Análisis__     
- Variable numérica discreta

- La mayoría de estudiantes que respondió 0 horas semanales de estudio tradicional nos da a entender que no estudian de la manera tradicional.

- Podemos visualizar que las horas máximas de estudio tradicional llegan hasta 30 como máximo dentro de los encuestados.

- El tiempo máximo de estudio tradicional de los encuestados suelen estar entre 1 a 8 horas semanales.

- A partir de las 21 horas semanales de estudio tradicional, el numero de encuestados comienza a decrecer.    

- Cuando calculamos el rango intercuartil, obtenemos que es Q3-q1 = 13, entonces obtenemos que hay una diferencia de 15 horas semanales por estudio máximo digital, es decir, esto muestra el rango que hay de horas semanales de estudio máximo tradicional entre el tercer cuartil y el primer cuartil de los encuestados.

- En este caso, indica que el 50% central de los encuestados tiene como tiempo maximo de estudio tradicional que varían en un rango de 13 horas semanales.


#### __MEDIDA DE RESPONSABILIDAD__


```{r echo=FALSE}
orden <- c("Nada responsable", "Poco responsable", "Neutral", "Responsable", "Muy responsable")
factor_medida_responsabilidad <- factor(datos_filtrados1$Medida_responsabilidad, levels = orden)

porcentaje_medida_responsabilidad <- table(factor_medida_responsabilidad) / length(factor_medida_responsabilidad) * 100

barp <- barplot(porcentaje_medida_responsabilidad,
                xlab = "Medida de responsabilidad",
                ylab = "Porcentaje",
                main = "Porcentaje de Medida de responsabilidad",
                ylim = c(0, 45),
                col = rainbow(5),
                cex.axis = 0.75,
                cex.names = 0.70,
                border = "gray1")

legend("topleft", legend = orden, fill = rainbow(5), cex = 0.9)
text(barp, porcentaje_medida_responsabilidad, labels = paste0(round(porcentaje_medida_responsabilidad, 2), "%"), pos = 3)


```
     
##### - __Análisis__
-De acuerdo al dato de frecuencias de los estudiantes encuestados la cuarta parte considera que tienen una medida de responsabilidad Neutral
-De acuerdo al dato de frecuencias de los estudiantes encuestados la otra cuarta parte considera que tienen una medida de responsabilidad Responsable
-De acuerdo al dato de frecuencias de los estudiantes encuestados la mitad aproximadamente considera que tienen una medida de responsabilidad de mur responsable, poco responsable y nada responsable.


#### __PERCEPCIÓN DE EFECTIVIDAD__   
 
```{r echo=FALSE}
# Calcular porcentajes
n.i_e <- table(datos_filtrados1$Percepcion_efectividad)
porcentaje_ni_e <- n.i_e / sum(n.i_e) * 100

barp <- barplot(porcentaje_ni_e,
                ylab = "Porcentaje",
                xlab = "Percepción_efectividad",
                main = "Porcentaje de Percepción de efectividad de la toma de apuntes digitales",
                col = c("green4", "orange3", "yellow4"),
                cex.axis = 0.75,
                cex.names = 0.75,
                ylim = c(0, 70),
                border = "gray1")

legend("topleft", legend = rownames(n.i_e), fill = c("green4", "orange3", "yellow4"), cex = 0.9)
text(barp, porcentaje_ni_e, labels = paste0(round(porcentaje_ni_e, 2), "%"), pos = 3)


```

##### - __Análisis__

- Menos del 10 % tiene una percepción negativa de la efectividad de las herramientas digitales
- Aproximadamente el 50 % tiene una percepción de efectividad positiva de las herramientas digitales
- Más del 40 % de encuestados tiene una percepción neutral respecto a la efectividad de las herramientas digitales    



#### __TIEMPO DE DEMORA__

```{r echo=FALSE}
datos_filtrados1$Nivel_confianza <- factor(datos_filtrados1$Nivel_confianza,
                                          levels = c("Poco confiable", "Neutral", "Confiable", "Muy confiable"))

hist(datos_filtrados1$Tiempo_de_demora, 
     xlab = "Tiempo de Demora (min)",
     ylab = "Frecuencia",
     main = "Distribución de Tiempo de Demora")

```
#### __TIEMPO DE DEMORA__

```{r}
boxplot(datos_filtrados1$Tiempo_de_demora, 
        ylab = "Tiempo de Demora",
        main = "Boxplot de Tiempo de Demora")
```

```{r}
summary(datos_filtrados1$Tiempo_de_demora)
```

##### - __Análisis__
- El promedio nos dice que la mayoría de encuestados se demora alrededor de 13 minutos para poder buscar fuentes confiables en línea.   

- Tiene un rango de 1 hasta 120 minutos, es decir, que se pueden demorar hasta 2 horas en buscar fuentes confiables.

- Hay muy pocos encuestados que sobrepasan los 30 minutos de búsqueda de fuentes confiables.

#### __NIVEL DE CONFIANZA__
```{r echo=FALSE}

n.i_n <- table(datos_filtrados1$Nivel_confianza)
porcentaje_ni_n <- n.i_n / sum(n.i_n) * 100

barp_3 <- barplot(porcentaje_ni_n, 
        xlab = "Nivel de Confianza",
        ylab = "Frecuencia",
        main = "Frecuencia de Nivel de Confianza",
        ylim = c(0, 85), 
        col = rainbow(4),
        cex.axis = 0.75,
        cex.names = 0.75,
        border = "gray1")
text(barp_3, porcentaje_ni_n, labels = paste0(round(porcentaje_ni_n, 2), "%"), pos = 3)

```


#### __CAPACITACIÓN_INC__ 
  
```{r echo=FALSE}
n.i_c <- table(datos_filtrados1$Capacitacion_INC)
porcentaje_ni_c <- n.i_c / sum(n.i_c) * 100

barp <- barplot(porcentaje_ni_c,
                ylab = "Porcentaje",
                xlab = "Capacitación_INC",
                main = "Frecuencia de capacitación_INC",
                col = rainbow(3),
                cex.axis = 0.75,
                cex.names = 0.75,
                ylim = c(0, 100),
                border = "gray1",
                names.arg = "")

legend("topleft", legend = rownames(n.i_c), fill = rainbow(3), cex = 0.8)

text(barp, porcentaje_ni_c, labels = paste0(round(porcentaje_ni_c, 2), "%"), pos = 3)


```

 
 

##### - __Análisis__ 
- Menos de un 25 % asegura no haber recibido formación para mitigar la información no confiable en línea

- Alrededor de un 75 % tiene capacitación para mitigar la información no confiable en línea, ya sea una capacitación por universidad o por otra institución o lugar

- Aproximadamente un 47 % ha obtenido la capacitación de mitigación de información no confiable en línea por medio de la universidad


#### __- Relación entre dos variables que responden a los objetivos__ 

#### __EDAD y MEDIDA DE RESPONSABILIDAD__  

 
```{r echo=FALSE}
DF1_mresp <- filter (datos_filtrados1, datos_filtrados1$`Medida_responsabilidad` != "No")
mis_colores <- c("red", "green", "blue", "orange", "pink")
nuevo_orden <- c("Nada responsable", "Poco responsable", "Neutral", "Responsable", "Muy responsable")

DF1_mresp$Medida_responsabilidad <- factor(DF1_mresp$Medida_responsabilidad, levels = nuevo_orden)

plot(factor(DF1_mresp$`Medida_responsabilidad`), DF1_mresp$Edad, 
     xlab = "Medida de responsabilidad", 
     ylab = "Edad", 
     main = "Edades de alumnos con respecto a las medidad de responsabilidad" , 
     col=mis_colores, 
     cex=1, 
     pch=8,
     cex.axis = 0.7) # Aquí se agrega el argumento cex.axis







```
 
##### - __Análisis__

-Al relacionar la edad con la medida de responsabilidad se obervan algunos datos importantes:
--La mediana de los estudiantes que se consideran muy responsables es de 20 años
--La mediana de los estudiantes que se consideran nada responsable es de 19,5 años
--La mediana de los estudiantes que se consideran neutral es de 18,6 años
--La mediana de los estudiantes que se consideran poco responsable es de 18,5 años
--La mediana de los estudiantes que se consideran responsable es de 18 años
 
#### __EDAD y CAPACITACIÓN_INC__  
 
```{r echo=FALSE}
DF2_cap <- filter(datos_filtrados1, datos_filtrados1$Capacitacion_INC != "No")
mis_colores <- c("red3", "lightblue3", "pink4", "orange4", "yellow3")
par(mar = c(4, 4, 4, 2)) # Ajustar los márgenes
plot(factor(DF2_cap$Capacitacion_INC), DF2_cap$Edad, xlab = "", ylab = "Edad", main = "Edad y Tasa de capacitación en Información no confiable", col = mis_colores, cex = 2, pch = 8,
     xaxt = "n") # Se establece xaxt = "n" para eliminar las etiquetas en el eje x


legend("topright", legend = levels(factor(DF2_cap$Capacitacion_INC)), fill = mis_colores, cex = 0.6)


title(ylab = 1.5)




```
  
  
#### __TIEMPO DE DEMORA y NIVEL DE CONFIANZA__ 
 
```{r echo=FALSE}
media_demora <- tapply(datos_filtrados1$Tiempo_de_demora, datos_filtrados1$Nivel_confianza, mean)

barplot(media_demora, ylim = c(0, max(media_demora) * 1.1),
        xlab = "Nivel de Confianza", ylab = "Tiempo de Demora Promedio (min)",
        main = "Tiempo de Demora Promedio por Nivel de Confianza",
        col = mis_colores, # Asignar el vector de colores al argumento col
        cex.names = 0.75) # Asignar el valor 0.5 al argumento cex.names
        
        
       
        

text(1:length(media_demora), media_demora, labels = round(media_demora, 2), pos = 3)


```

 
##### - __Análisis__ 
- Al contrastar estos dos conjuntos de datos, se encuentra una correlación interesante. Se observa que aquellos estudiantes que informaron un tiempo de demora aproximado de 20 minutos en consultar una fuente tienen un nivel de confianza más bajo en comparación con los que consultan en menor tiempo. A medida que aumenta el nivel de confianza, se observa una disminución en el tiempo de demora en analizar una fuente. Por lo tanto, se deduce que las personas que tienen menos confianza en la fuente tienden a demorarse más en su análisis.


#### __PERCEPCIÓN DE EFECTIVIDAD Y HERRAMIENTAS DIGITALES__ 

```{r echo=FALSE}
mosaicplot(table(datos_filtrados1$Frecuencia_herramientas_D, datos_filtrados1$Percepcion_efectividad), las = 1, main = "Efectividad", xlab= "Herramientas Digitales", ylab= "Percepción")
```
##### - __Análisis__

- El uso de herramientas digitales en la opción de a veces, con frecuencia, rara vez y siempre, presentan una tendencia de una percepción neutral y positiva respecto al uso de las herramientas digitales

- La percepción de efectividad negativa es muy poco frecuente en todas las opciones

- Se puede contrastar como el uso de herramientas digitales en la opcion de a veces predomina la percepción neutral y en la opcion de siempre predomina la percepción positiva




#### __ACCIONES RESPONSABLES Y CAPACITACIÓN__ 


```{r echo=FALSE}
categorias <- unique(datos_filtrados1$Acciones_responsables)

# Crear etiquetas cortas para las categorías
etiquetas_cortas <- c("A1", "A2", "A3", "A4") # Puedes personalizar las etiquetas cortas aquí

datos_filtrados1$Acciones_responsables <- factor(datos_filtrados1$Acciones_responsables, levels = categorias, labels = etiquetas_cortas)

categorias_cap <- unique(datos_filtrados1$Capacitacion_INC)

etiquetas_cortas_cap <- c("C1", "C2", "C3") # Puedes personalizar las etiquetas cortas aquí

datos_filtrados1$Capacitacion_INC <- factor(datos_filtrados1$Capacitacion_INC, levels = categorias_cap, labels = etiquetas_cortas_cap)

mosaicplot(table(datos_filtrados1$Capacitacion_INC, datos_filtrados1$Acciones_responsables), las = 1, main = "Estrategias", xlab = "Capacitacion", ylab = "Acciones responsables", color = c("red", "blue", "green", "orange"))

legend <- NULL
```
 
 
 __C1__ : No, nunca he recibido capacitación en este tema.    
 __C2__ : Sí, en la universidad.  
 __C3__ : Sí, en otra institución o lugar.  
 
 __A1__ : No la utilizo y busco fuentes confiables.  
 __A2__ : La utilizo, pero la verifico con otras fuentes confiables.  
 __A3__ : La utilizo tal cual, sin verificar su veracidad.  
 __A4__ : La comparto en mis redes sociales o con otros sin verificar su veracidad.  

 
 

##### - __Análisis__
- Independientemente de la capacitación si es adecuada o no, la mayoría de encuestados tiende a conocer las normas de propiedad intelectual

- Los encuestados en general tienden a preocuparse por las normas de propiedad intelectual

- La mayoría de encuestados citan las fuentes de manera adecuada

- Los encuestados también muestran un menor uso de recursos con licencias abiertas en comparación de la citación de fuente de manera adecuada


##  **III. ANÁLISIS PROBABILÍSTICO**

### __Probabilidad Empírica__


__Datos importantes__

```{r}
N_total <- nrow(datos_filtrados1)

N_total

fr1 <- table(datos_filtrados1$Nivel_confianza)
fr1

fr1_A1 <- fr1["Poco confiable"]
fr1_A1

fr1_A2 <- fr1["Neutral"]
fr1_A2

fr1_A3 <- fr1["Confiable"]
fr1_A3

fr1_A4 <- fr1["Muy confiable"]
fr1_A4

fr2 <- table(datos_filtrados1$Percepcion_efectividad)
fr2

fr2_A1 <- fr2["Negativa"]
fr2_A1

fr2_A2 <- fr2["Neutral"]
fr2_A2

fr2_A3 <- fr2["Positiva"]
fr2_A3
```


#### __NIVEL DE CONFIANZA__ 

Experimento : Seleccionar encuestados de los estudiantes de UTEC matriculados en el ciclo 2023 - 1 y observar
su percepción de confianza respecto a la veracidad de información que encuentra en línea

__- Espacio de resultados__ 

Ω = { Poco confiable,Neutral,Confiable,Muy confiable} -> 
$$n(Ω) = 4$$

__- Eventos atómicos:__

- A1 = Seleccionar a un estudiante que tenga una percepción de poca confiabilidad respecto a la veracidad de la información que encuentra en línea

- A2 = Seleccionar a un estudiante que tenga una percepción neutral respecto a la veracidad de la información que encuentra en línea

- A3 = Seleccionar a un estudiante que tenga una percepción de confiabilidad respecto a la veracidad de la información que encuentra en línea

- A4 = Seleccionar a un estudiante que tenga una percepción de mucha confiabilidad respecto a la veracidad de la información que encuentra en línea

__- Función probabilidad (Empírica)__

P(A1) = 0.07 =  7 %

P(A2) = 0.48 = 48 %

P(A3) = 0.4  = 40 %

P(A4) = 0.05 =  5 %


x       A1       A2       A3       A4

f(x)    7/100    48/100   40/100   5/100

__- Conclusión:__ 

Se demostró por parte de los estudiantes una percepción positiva respecto a la veracidad de información encontrada en línea, sin embargo hay muy pocas personas que se encuentran en los extremos de una percepción poco confiable y muy confiable, los estudiantes prefieren mantenerse al margen y muestran una amplia acogida a la veracidad de la información en línea.  


```{r}
PA1 = round(fr1_A1/N_total, 2)

PA1

PA2 = round(fr1_A2/N_total, 2)

PA2

PA3 = round(fr1_A3/N_total, 2)

PA3

PA4 = round(fr1_A4/N_total, 2)

PA4
```



#### __PERCEPCIÓN DE EFECTIVIDAD__ 

Experimento: Seleccionar encuestados de los estudiantes de UTEC matriculados en el ciclo 2023 - 1 y observar
su percepción de efectividad de la toma de apuntes digitales respecto a la toma de apuntes tradicionales

__- Espacio de resultados__ 

Ω = { Negativa,Neutral,Positiva} -> 
$$n(Ω) = 3$$

__- Eventos atómicos:__

- A1 = Seleccionar un estudiante que presenta una percepción negativa de la toma de apuntes digitales

- A2 = Seleccionar un estudiante que presenta una percepción neutral de la toma de apuntes digitales

- A3 = Seleccionar un estudiante que presenta una percepción positiva de la toma de apuntes digitales

__- Función probabilidad (Empírica)__

P(A1) = 0.03 =  3 %

P(A2) = 0.46 = 46 %

P(A3) = 0.51 = 51 %


x        A1     A2      A3

f(x)     3/100  46/100  51/100

__- Conclusión:__ 

Se demostró una percepción positiva respecto a la toma de apuntes digitales vs la toma de apuntes tradicional, sin embargo no demuestra si es superior a la toma de apuntes tradicionales,pero si muestra gran acogida por casi la mitad de estudiantes que le dieron un visto positivo.


```{r}
PB1 = round(fr2_A1/N_total, 2)

PB1

PB2 = round(fr2_A2/N_total, 2)

PB2

PB3 = round(fr2_A3/N_total, 2)

PB3
```


### __Probabilidad Condicional__

#### __EVENTOS INDEPENDIENTES__

__- Utilizaremos las siguientes variables para crear eventos de interés__

- Variable 1 = Medida_responsabilidad
- Variable 2 = Sexo

__- Experimento__

Si seleccionamos al azar de esta población y se encuentra que es hombre.
¿CUÁL ES LA PROBABILIDAD DE QUE SEA MUY RESPONSABLE AL MOMENTO DE MITIGAR INFORMACIÓN NO CONFIABLE?

#### __- Primer paso: Identificar los eventos de cada variable__

- A: Seleccionar a un estudiante de que se perciba como alguien muy responsable para mitigar información no confiable
- B: Seleccionar a un estudiante que sea de sexo masculino

#### __- Segundo paso: Identificar si los eventos son independientes__
Para ello creamos nuestra tabla de contingencia.
__- Creamos nuestra tabla de contingencia de EVENTOS__

```{r echo=FALSE}
datos_filtrados1 <- datos_filtrados1[datos_filtrados1$Sexo != "Otro", ]
datos2 <- datos_filtrados1[1:163,]

n_total <- nrow(datos2)
print(n_total)

n_masculino <- sum(datos2$Sexo == "Masculino")
n_femenino <- sum(datos2$Sexo == "Femenino")

tabla_contingencia <- table(datos2$Medida_responsabilidad, datos2$Sexo)

prop_tabla_contingencia <- prop.table(tabla_contingencia)
tabla_contingencia <- prop_tabla_contingencia
fila_complemento <- prop_tabla_contingencia[2, ] + prop_tabla_contingencia[3, ] + prop_tabla_contingencia[4, ] + prop_tabla_contingencia[5, ]
rownames(tabla_contingencia)[2] <- "Complemento"
tabla_contingencia[2, ] <- fila_complemento
tabla_contingencia <- tabla_contingencia[-c(3:5), ]
suma_columnas <- colSums(tabla_contingencia)
suma_filas <- rowSums(tabla_contingencia)
tabla_contingencia <- cbind(tabla_contingencia, suma_columnas)
tabla_contingencia <- rbind(tabla_contingencia, c(suma_filas, sum(suma_filas)))
colnames(tabla_contingencia)[3] <- "Suma"
rownames(tabla_contingencia)[3] <- "Suma"

tabla_contingencia <- round(tabla_contingencia, digits = 4)
tabla_contingencia[1, 3] <- round(suma_filas[1], digits = 4)
tabla_contingencia[2, 3] <- round(suma_filas[2], digits = 4)
tabla_contingencia[3, 1] <- round(suma_columnas[1], digits = 4)
tabla_contingencia[3, 2] <- round(suma_columnas[2], digits = 4)

print(tabla_contingencia)
datos_faltantes <- sum(is.na(datos_filtrados1$Sexo))
print(datos_faltantes)

```

__- Obtenemos los datos de nuestra tabla__

```{r}
p_a <- 0.1227 # Probabilidad de A
p_b <- 0.5460 # Probabilidad de B 
p_a_b <- 0.0675 # Probabilidad de A ∩ B
p_total <- 1 # Probabilidad total

```

__- Para verificar la independencia entre los eventos A y B, usamos el siguiente criterio__

$$Si P(A ∩ B) = P(A) * P(B)$$
```{r}
p_a_por_p_b <- p_a * p_b
if (round(p_a_b,2) == round(p_a_por_p_b,2)) { print("Los eventos son independientes") 
} else { print("Los eventos son dependientes") }
```

$$P(A ∩ B) ≠ P(A) * P(B)$$
$$0.06 = 0.06$$
__- Conclusión:__ Entonces los eventos son dependientes.

#### __- Tercer paso: Calcular la probabilidad condicional__

Para calcular la probabilidad condicional de A dado B usando la siguiente fórmula:
$$P(A|B) = P(A ∩ B) / P(B)$$

__- Definimos los eventos y sus frecuencias__

```{r}
A <- "Ser muy responsable al momento de mitigar información no confiable"
B <- "Ser hombre"
p_a <- 0.067 # Probabilidad de A 
p_b <- 0.5460 # Probabilidad de B
p_a_b <- 0.0675 # Probabilidad de A  
p_total <- 1 # Frecuencia total de personas
```

__- Calculamos la probabilidad condicional__

```{r}
p_a_dado_b <- p_a_b / p_b # Probabilidad de A dado B
```

__- Imprimimos el resultado__

```{r}
print(paste("La probabilidad de", A, "dado que", B, "es", round(p_a_dado_b, 2)))
print(paste("La probabilidad de", A, "dado que", B, "es", round(p_a_dado_b * 100, 2), "%"))
```

__- CONCLUSIÓN__ : Esto significa que hay un 12.36% de probabilidad de que una persona sea muy responsable al momento de mitigar información no confiable, dado que es hombre.


#### __- Cuarto paso: Teorema de Bayes__

__- Aplicamos el teorema de la probabilidad total__

Este teorema nos dice que la probabilidad de un evento A se puede obtener sumando las probabilidades condicionales de A dado cada evento del partición del espacio muestral.
En este caso, podemos usar el género como la partición, es decir, B y su complemento B^c.
Entonces, la probabilidad de A se puede expresar como:

$$P(A)=P(A∣B)*P(B)+P(A∣Bc )*P(Bc)$$

__- Para calcular P(A|B^c), podemos usar la definición de probabilidad condicional y la tabla:__

$$P(A∣Bc)=P(A∩Bc/P(Bc)=0.0552/0.4540≈0.1216$$

__- Luego, para obtener P(A):__

```{r}
p_a_dado_b_c <- 0.0552 / 0.4540 # Probabilidad de A dado B complemento
p_a <- p_a_b / p_b + p_a_dado_b_c * (1 - p_b) # Probabilidad total de A
```

__- Ya tenemos todos los valores necesarios para aplicar esta fórmula, así que obtenemos P(B|A):__

```{r}
p_b_dado_a <- p_a_b / p_b / p_a # Probabilidad de B dado A
```

__- Imprimir el resultado__

```{r}
print(paste("La probabilidad de", B, "dado que", A, "es", round(p_b_dado_a, 2)))
print(paste("La probabilidad de", B, "dado que", A, "es", round(p_b_dado_a * 100, 2), "%"))
```


#### __EVENTOS DEPENDIENTES__

__- Utilizaremos las siguientes variables para crear eventos de interés__

Variable 1 = Percepción de efectividad      
Variable 2 = Herramientas digitales         

__- Experimento__

```{r}
fadada <- table(datos_filtrados1$Herramientas_D)
fadada
```

```{r}
fadadaa <- table(datos_filtrados1$Percepcion_efectividad)
fadadaa
```

- Si seleccionamos al azar de esta población y se encuentra a un estudiante con una percepción positiva sobre las herramientas de toma de notas.
¿CUÁL ES LA PROBABILIDAD DE QUE TENGA UNA PERCEPCIÓN POSITIVA SOBRE LAS HERRAMIENTAS DE NOTAS?

#### __- Primer paso: Identificar los eventos de cada variable__

- A: Seleccionar a un estudiante que tenga una percepción positiva .
- B: Seleccionar a un estudiante que utilice herramientas de toma de notas para estudiar de manera digital

#### __- Segundo paso: Identificar si los eventos son dependientes__

Para ello:

__- Creamos nuestra tabla de contingencia de EVENTOS__

```{r}


```

__- Obtenemos los datos de nuestra tabla:__

```{r}

```

__- Para verificar la independencia entre los eventos A y B, usamos el siguiente criterio:__

$$Si P(A ∩ B)  =!  P(A) * P(B)$$
```{r}

```

$$P(A ∩ B) = P(A) * P(B)$$
$$ = $$
__- Conclusión:__ Entonces los eventos son dependientes.

#### __Tercer paso: Calcular la probabilidad condicional__

__- Para calcular la probabilidad condicional de A dado B usando la siguiente fórmula:__

$$P(A|B) = P(A ∩ B) / P(B)$$
__- Donde P(A ∩ B) es la probabilidad conjunta de A y B, y P(B) es la probabilidad marginal de B.__

```{r}

```

__- Conclusión__ : 

#### __- Cuarto paso: Teorema de Bayes__

- Para calcular la probabilidad condicional usando el teorema de Bayes usamos la siguiente fórmula:
$$P(B|A) = P(A|B) * P(B) /  P(A) $$

### __VARIABLES DISCRETAS__

- Datos importantes - Opciones únicas de las variables

```{r}
# Cantidad total de estudiantes encuestados
N_total

# Opciones únicas de la variable

va1 <- unique(datos_filtrados1$Percepcion_efectividad)

va1

# Opciones únicas de la variable

va2 <- unique(datos_filtrados1$Nivel_confianza)

va2
```
__- PRIMERA VARIABLE__

#### __- Primer paso: Definir que distribución se usará__

__- Variable: Percepción_de_efectividad - categórica nominal__

__- Distribución: Binomial__

__Notación:__

$$x ~ Bin(n,p)$$

#### __- Segundo paso: Definir la variable aleatoria__

- X: Cantidad de estudiantes que presentan una perspectiva positiva (éxitos) de los 164 encuestados.

#### __- Tercer paso: Identificar parámetros__

$$x ~ Bin(n,p)$$

__Éxito:__ Que el estudiante seleccionado tenga una perspectiva positiva de la toma de apuntes digitales respecto a la toma de apuntes tradicionales 

- n = 164

- p = 0.51 = 51 % (Probabilidad de éxito)


```{r}
# Probabilidad de éxito

fr2 <- table(datos_filtrados1$Percepcion_efectividad)

fr2_A3 <- fr2["Positiva"]

Pe1 <- round(fr2_A3/N_total, 2)

Pe1
```

#### __- Cuarto paso: Construir densidad__

```{r}

# Parámetros de la distribución binomial
n <- 164  # Número de observaciones
p <- 0.51  # Probabilidad de éxito

# Valores del eje x (número de éxitos)
x <- 0:n

# Valores de densidad para la distribución binomial
densidad <- dbinom(x, n, p)

# Graficar la densidad
plot(x, densidad, type = "h", lwd = 2, main = "Gráfica de Densidad Binomial",
     xlab = "Número de Éxitos", ylab = "Densidad")
```
     
#### __- Quinto paso: Validar las propiedades__

__- Valor esperado y varianza__

$$ = E(x) = n*p$$

$$σ2 = n*p(1-p)$$

```{r}
n <- 164  # Número de observaciones
p <- 0.51  # Probabilidad de éxito

# Valor esperado

E_x <- n * p

E_x

# Varianza
 
var <- (n*p)*(1-p)

var
```


#### __- sexto paso: Construir un ejemplo__

__Ejemplo__

En la universidad UTEC se desea conocer la probabilidad de que mas del 51% de estudiantes tengan una perspectiva neutral o negativa respecto a la toma de apuntes digitales. Se sabe que 164 estudiantes participaron en la encuesta.


```{r}

# Py + Px = 1


pbinom(83, 164, 0.49, lower.tail = FALSE, log.p = FALSE) 

pbinom(80, 164, 0.51, lower.tail = TRUE, log.p = FALSE)
```
__- Conclusión:__

Podemos ver que los dos resultados son iguales, entonces podemos decir que la distribución binomial esta bien ajustada en este caso ya que al verificar que dichas probabilidades son iguales estamos comprobando de que la P(a) es igual a su complemento.

### __2° VARIABLE__

#### __- Primer paso: Definir que distribución se usará__

__- Variable: Nivel_de_confianza - categórica ordinal__

__Distribución:__ Geométrica

__Notación:__	$$x ~ Geom(p)$$

#### - Segundo paso: Definir la variable aleatoria__

- x: Cantidad de estudiantes encuestados hasta encontrar uno con perspectiva de confiabilidad (éxito). 

#### __- Tercer paso: Identificar parámetros__

$$x ~ Geom(p)$$

__- Éxito:__ Encontrar un estudiante que tenga una perspectiva de confiabilidad respecto a la veracidad de información que encuentra en linea

- p = 0.4 = 40% (Probabilidad de éxito)

```{r}

fr3 <- table(datos_filtrados1$Nivel_confianza)

fr3_A3 <- fr3["Confiable"]

Pe2 <- round(fr3_A3/N_total, 2)

Pe2
```

#### __- Cuarto paso: Construir la densidad__

```{r}
# Parámetro de la distribución geométrica
n <- 164  # Número de observaciones
p <- 0.4  # Probabilidad de éxito
 
# Valores del eje x (número de ensayos)
x <- 0:n 

# Valores de densidad para la distribución geométrica
densidad <- dgeom(x, p)

# Graficar la densidad
plot(x, densidad, type = "h", lwd = 2, main = "Gráfica de Densidad Geométrica",
     xlab = "Número de observaciones", ylab = "Densidad")
```

#### __- Quinto paso: Validar parámetros__

__- Valor esperado y varianza__

$$μ = E(x) = 1/p$$		

$$σ2 = (1-p)/p2$$

```{r}

n <- 164  # Número de observaciones
p <- 0.4  # Probabilidad de éxito

# Valor esperado

E_x <- 1/p

E_x

# Varianza
 
var <- (1-p)/p^2 

var
```

#### __- Sexto paso: Construir ejemplo__

__- Ejemplo__

El 40% de los sujetos de los estudiantes mantienen una percepción de confiabilidad. Supongamos que los estudiantes llegan al azar para la encuesta del nivel de confianza respecto a la veracidad de información que encuentran en línea. Determinar la probabilidad de que el 18to estudiante tenga una percepción de confiabilidad. (Recien 10octavo-percepcion de confiabilidad, primer éxito)

__- Éxito:__ Encontrar un estudiante con percepción de confiabilidad

- x: Cantidad de estudiantes a evaluar hasta encontrar el (éxito). x = 18

- p = 0.4

- f(x=18) = 0.6^17 * 0.4 = 4.062398e-05

```{r}
dgeom(x=18, prob = 0.40)
```
__- Conclusión:__ Los números coinciden con la gráfica de la distribución geométrica, ya que mientras mayor sea el número de estudiantes a evaluar para recién conseguir uno que tenga una percepción de confiabilidad, menor sera el porcentaje de probabilidad porque es mucho más difícil encontrar casi ningun estudiante que tenga una percepción de confiabilidad en un rango amplio dentro del rango que se determina.



### __VARIABLES CONTINUAS__

- Datos importantes:

```{r}

# Cantidad total de estudiantes encuestados
N_total

# Opciones únicas de la variable

varia1 <- unique(datos_filtrados1$Tiempo_de_demora)

varia1 

# Opciones únicas de la variable

varia2 <- unique(datos_filtrados1$Tmax_estudio_digital)

varia2



```

###__Variable 1: Tiempo de demora__

#### __- Primer paso: Identificar gráficamente la variable Tiempo_de_demora__

```{r}

library(EnvStats)
epdfPlot(datos_filtrados1$Tiempo_de_demora, epdf.col = "red")  
```

#### __- Segundo paso: Validación__

__- Media ≅  Mediana__

$$(\overline {X}) ≅ Me$$

```{r}
# Vector con el primer y tercer cuartil
cuartiles <- c(0:120)
# Número de datos
n <- length(cuartiles)
# Suma de los datos
suma <- sum(cuartiles)
# Media aritmética
media <- suma / n
media

```


```{r}
Tiempo_de_demoraSort <- sort(datos_filtrados1$Tiempo_de_demora)
mediana <- median(Tiempo_de_demoraSort)
mediana
```

#### __- Verificación de la Media y Mediana__

__- Media y mediana diferentes__

- Debido a que la media resulta ser 60 y la mediana 10, podemos afirmar que no existe una curva normal, por lo tanto reducimos nuestra gráfica debido a que exista una cantidad significativa de alumnos que representa más de la mitad de encuestados que respondieron  que dedicaban un tiempo de 0 a 20 minutos al día para encontrar fuentes confiables.

__- Reducción de la gráfica__


```{r}
library(EnvStats)
epdfPlot(datos_filtrados1$Tiempo_de_demora, epdf.col = "red",xlim=c(0,20))
```
__- Nueva validación de Media ≅  Mediana__

$$(\overline {X}) ≅ Me$$

```{r}
# Vector con el primer y tercer cuartil
Cuartiles <- c(0,20)
# Número de datos
N <- length(Cuartiles)
# Suma de los datos
Suma <- sum(Cuartiles)
# Media aritmética
Meedia <- Suma / N
Meedia
# 10
```

```{r}
Tiempo_de_demoraSort <- sort(datos_filtrados1$Tiempo_de_demora)
mediana <- median(Tiempo_de_demoraSort)
mediana
```

__- Desviación estándar__

$$Sd$$
__- Para hallar la desviación estándar de una variable aleatoria Tiempo_de_demora, usamos la función *sd*__ 

```{r}
sd(datos_filtrados1$Tiempo_de_demora)
```

__- Varianza__

$$V({X}) ≅ Sd^2(Tiempo de demora)$$

__- Para hallar la varianza de una variable aleatoria Tiempo_de_demora, usamos la función *var*__


```{r}
var(datos_filtrados1$Tiempo_de_demora) 
```

- La varianza es  255.5254

__- Esperanza = __

$$E({X}) ≅ mean(Tiempo de demora)$$

__- Para hallar la esperanza de una variable aleatoria Tiempo_de_demora, usamos la función *mean*.__ 

```{r}
mean(datos_filtrados1$Tiempo_de_demora)
```
__- Otra manera de validar la esperanza__

```{r}
esperanza <- sum(datos_filtrados1$Tiempo_de_demora) / length(datos_filtrados1$Tiempo_de_demora)
esperanza

```

```{r}
summary(datos_filtrados1$Tiempo_de_demora)
```

#### __- Tercer paso__

Al validar nuestra variable aleatoria continua Tiempo_de_demora como una distribución normal, tenemos que:

- µ = mean(datos_filtrados1$Tiempo_de_demora) 
- σ = sd(datos_filtrados1$Tiempo_de_demora)
- X = Tiempo_de_demora
- N = Normal

$$X ≈ N(µ,σ)$$

```{r}
µ = mean(datos_filtrados1$Tiempo_de_demora) 
σ = sd(datos_filtrados1$Tiempo_de_demora)
µ
σ

```

```{r}
datos_filtrados1 
```

#### __- Cuarto paso__

__Plateamos el experimento:__ ¿cuál es la probabilidad de que un estudiante demore más de 10 min al consultar una fuente, si es que este estudia menos de 30 min al día?


```{r}

mu_demora <- mean(datos_filtrados1$Tiempo_de_demora)
desviacion_demora <- sd(datos_filtrados1$Tiempo_de_demora)

prob_demora_mayor_10 <- 1 - pnorm(10, mean = mu_demora, sd = desviacion_demora, lower.tail = FALSE)

print(paste("Probabilidad de que el tiempo de demora sea mayor a 10 es :", round(prob_demora_mayor_10, 2)))

```


### __- VARIABLE 2: TIEMPO DE ESTUDIO MÁXIMO DIGITAL__

#### __- Primer paso: Identificar graficamente la variable Tmax_estudio_digital__

```{r}
library(EnvStats)

epdfPlot(datos_filtrados1$Tmax_estudio_digital, epdf.col = "blue")
```

#### __- Segundo paso: Validación__

__- Media ≅  Mediana__

$$(\overline {X}) ≅ Me$$
```{r}
# Vector con el primer y tercer cuartil
Cuartiles <- c(15,30)
# Número de datos
N <- length(Cuartiles)
# Suma de los datos
Suma <- sum(Cuartiles)
# Media aritmética
Meedia <- Suma / N
Meedia
# 10
```


```{r}
Tmax_estudio_digitalSort <- sort(datos_filtrados1$Tmax_estudio_digital)
Mediana <- median(Tmax_estudio_digitalSort)
Mediana
```

#### __- Verificación de la Media y Mediana__

__- Media y mediana diferentes__

- Cómo podemos observar la media es 22.5 y la mediana es 20, por lo que podemos afirmar que no existe una curva normal, sin embargo, la mayor cantidad de nuestros encuestados respondieron que dedican entre 0 y 40 horas a la semana de tiempo máximo de estudio con dispositivos digitales, razón por la cuál decidimos reducir nuestra gráfica entre estos valores.

__- Reduccción de la gráfica__

```{r}
library(EnvStats)

epdfPlot(datos_filtrados1$Tmax_estudio_digital, epdf.col = "blue",xlim=c(0,40))
```
__- Nueva validación de Media ≅  Mediana__

$$(\overline {X}) ≅ Me$$

```{r}
# Vector con el primer y tercer cuartil
Cuartiles <- c(0,40)
# Número de datos
N <- length(Cuartiles)
# Suma de los datos
Suma <- sum(Cuartiles)
# Media aritmética
Meedia <- Suma / N
Meedia
# 10
```
```{r}
Tmax_estudio_digitalSort <- sort(datos_filtrados1$Tmax_estudio_digital)
Mediana <- median(Tmax_estudio_digitalSort)
Mediana
```
__- Desviación estándar__

$$Sd$$
- Para hallar la desviación estándar de una variable aleatoria Tmax_estudio_digital, usamos la función *sd*. 

```{r}
sd(datos_filtrados1$Tmax_estudio_digital)
```


__Varianza__

$$V({X}) ≅ Sd^2(Tiempo de max.estudiodigital)$$

- Para hallar la varianza de una variable aleatoria Tmax_estudio_digital, usamos la función *var*.

```{r}
var(datos_filtrados1$Tmax_estudio_digital) 
```

- La varianza es  206.5586

__- Esperanza = __

$$E({X}) ≅ mean(Tmax.estudiodigital)$$

- Para hallar la esperanza de una variable aleatoria Tmax.estudiodigital, usamos la función *mean*. 

```{r}
mean(datos_filtrados1$Tmax_estudio_digital)
```
__- Otra manera de validar la esperanza__

```{r}
esperanza <- sum(datos_filtrados1$Tmax_estudio_digital) / length(datos_filtrados1$Tmax_estudio_digital)
esperanza
```


```{r}
summary(datos_filtrados1$Tmax_estudio_digital)
```


#### __- Tercer paso__

Al validar nuestra variable aleatoria continua Tmax_estudio_digital como una distribución normal, tenemos que:

- U <- µ = mean(datos_filtrados1$Tmax_estudio_digital) 
- O <- σ = sd(datos_filtrados1$Tmax_estudio_digital)
- X = Tiempo_de_demora
- N = Normal

$$X ≈ N(µ,σ)$$

```{r}
U = mean(datos_filtrados1$Tmax_estudio_digital) 
O = sd(datos_filtrados1$Tmax_estudio_digital)
U
O

```
#### __- CUARTO PASO__

__Plateamos el experimento:__ ¿Cuál es la probabilidad de que un estudiante estudie digital en un tiempo mayor a 30 minutos?

```{r}
mu_tmax <- mean(datos_filtrados1$Tmax_estudio_digital)
desviacion_tmax <- sd(datos_filtrados1$Tmax_estudio_digital)
prob_tmax_menor_30 <- pnorm(30, mean = mu_tmax, sd = desviacion_tmax, lower.tail = FALSE)
print(paste("Probabilidad de que Tmax_estudio_digital sea menor a 30 es:", round(prob_tmax_menor_30, 2)))
```



```{r}
prob_conjunta <- prob_demora_mayor_10 * prob_tmax_menor_30
print(paste("Probabilidad conjunta de ambas condiciones es:", round(prob_conjunta, 3)))
```

### __CONCLUSIONES__

- Hemos podido analizar que la percepción de efectividad y nivel de satisfacción respecto a las herramientas digitales, son muy aceptadas por la comunidad estudiantil de Utec en el ciclo 2023-1, sin embargo existe una mitad importante que se mantiene con una percepción neutra, esto nos dice que si bien la efectividad y satisfacción son positivas aún queda una cantidad importante de estudiantes que siguen en una posición neutral.

- Si bien hay una grna cantidad que tiene una percepción de confiabilidad respecto a la veracidad de la información en línea, no es suficiente como para considerarlo un resultado positivo, ya que nisiquiera se llega a obtener al menos un 50% que mantenga un perspectiva de confiabilidad, y si analizamos los extremos podemos ver que la perspectiva de poco confiable superar nimiamente a la de muy confiable.

- Pudimos identificar que una cantidad mayor al 70% de estudiantes encuestados se encuentran bien capacitados respecto al conocimiento y cumplimiento de las regulaciones de propiedad intelectual en el ambiente digital.



