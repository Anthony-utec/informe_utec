---
title: "***Análisis comparativo de los salarios de Data Science entre 2020-2023 a nivel internacional***"
output: 
  html_document:
    theme: flatly
    toc: TRUE
    toc_float:
      collapsed: FALSE
    number_sections: TRUE
---

# **Introducción**

En la actualidad, la ciencia de datos se ha convertido en una de las áreas más prometedoras y de mayor crecimiento en el mundo empresarial. Con la creciente demanda de profesionales altamente capacitados en esta disciplina, los salarios de los expertos en ciencia de datos también han aumentado significativamente. Por lo tanto, el análisis de los salarios en la industria de la ciencia de datos se ha convertido en una tarea crítica para entender la dinámica de esta disciplina y para tomar decisiones empresariales informadas.

Este informe tiene como objetivo proporcionar un análisis detallado de los datos obtenidos acerca de los salarios de ciencia de datos en sus diferentes posiciones de trabajo, con el fin de obtener información relevante sobre los salarios de los profesionales de la ciencia de datos en todo el mundo. El informe incluirá un análisis exploratorio de datos (EDA), así como un análisis estadístico detallado de los datos. Este análisis permitirá obtener una comprensión preliminar de la distribución de los salarios, las tendencias y los factores que influyen en los salarios de los profesionales de la ciencia de datos. El análisis estadístico permitirá identificar las relaciones significativas entre los salarios y otros factores relevantes, como la experiencia, la formación académica, la ubicación geográfica y los lenguajes de programación utilizados.

## Relevancia

Actualmente, Data Science es una carrera muy demandada en el país y en general, en el mundo. Podemos afirmar que es una carrera en gran crecimiento debido a las necesidades actuales a nivel nacional e internacional. De igual manera, Data Science es una carrera que garantiza un salario considerable a los expertos de dicha rama, esto como resultado de una gran demanda de profesionales en el sector. 

Es así que consideramos importante realizar un análisis de cuánto puede llegar a ganar un experto en Data Science, teniendo en cuenta diversos factores, como su nivel de experiencia, el tipo de rol que ejerce, su país de residencia, entre otros tantos. De esta forma, podemos crear relaciones que expliquen correctamente los salarios que pueden lograr obtener los expertos en Ciencia de Datos.

## Objetivos

### Objetivo general

El objetivo general de este estudio estadístico es analizar los salarios en la industria de la ciencia de datos entre 2020-2023, con el fin de identificar patrones, tendencias y factores que influyen en los salarios de los profesionales de la ciencia de datos. El estudio también tiene como objetivo proporcionar información útil para las empresas y profesionales de la industria de la ciencia de datos, así como para investigadores y académicos interesados en el tema.

### Objetivos específicos
- Analizar la distribución de los salarios en la industria de la ciencia de datos desde el año 2020 hasta el 2023 y representar gráficamente los datos obtenidos.

- Identificar las áreas geográficas con los salarios más altos y más bajos en la industria de la ciencia de datos.

- Analizar la relación entre la formación académica y los salarios en la industria de la ciencia de datos.

## Contexto

Para entender de mejor forma el tema que vamos a analizar, ponemos en consideración que al tratarse de la carrera de Data Science, algunos términos podrían ser nuevos o quizá poco familiares para el lector. Básicamente son términos como el nivel de experiencia, el tipo de empleo, el rol en el trabajo, y la cantidad de trabajo remoto. Para ello, al inicio del análisis descriptivo de cada variable, se ha decidido realizar algunas precisiones, sobretodo en aquellas variables que podrían generar confusiones o dudas, para que el entendimiento del tema propuesto sea el mejor posible.

# **Datos**

## Recolección de datos

Para la recolección de datos, usamos la página KAGGLE para seleccionar un dataset sobre un tema en particular, que en esta ocasión trata sobre los salarios de Ciencia de Datos. Este tema fue del interés de todo el grupo luego de revisar las distintas opciones disponibles en el sitio web.

[Archivo de estudio en formato CSV](https://docs.google.com/spreadsheets/d/1qR07e2MtO135delNhWx-B-XJTj1yjeVmOzFIpe5Z9-0/edit?usp=sharing)

```{r}
library(readr)
data=read_csv("salarios_data_science.csv")
```


## Población, muestra y muestreo

Teniendo en cuenta que nuestra base datos fue diseñada previamente, podemos detallar entonces:

### Población

La **población** toma los registros de los salarios de empleados de Data Science desde 2020 hasta el 2023 a nivel internacional 

```{r}
dim(data)
```

Las dimensiones de la población es de 3755 filas u observaciones y 11 columnas, que representan la cantidad de variables que manejamos

### Unidad muestral

Empleados de Data Science desde 2020 hasta el 2023 a nivel internacional 

### Muestra

Hemos decidido sacar una muestra de 1000 de los salarios registrados en el dataset, de forma aleatoria.

```{r}
m <- data[sample(nrow(data), 1000), ]
```

Luego extraemos la muestra hacia un archivo CSV. Así evitamos una muestra que varíe en muchas ocasiones.

```{r}
library(readr)

muestra=read_csv("muestra.csv")
muestra
```

Entonces, calculamos las dimensiones de la muestra que se extrajo finalmente:

```{r}
dim(muestra)
```

La función dim() me indica que la muestra presenta 1000 filas u observaciones y 11 columnas, que representan la cantidad de variables que manejamos.

### Muestreo

De acuerdo a nuestro dataset y a la muestra que obtuvimos, podemos afirmar que utilizamos un muestreo aleatorio simple.

```{r}
nrow(muestra)
```


## Variables

### Presentación de variables

Variables      | Descripción                                                   | Tipo                                            | Restricción
-------------- | --------------------------------------------------------------------------------------------------------------- | ----- | -------
*work_year*     | El año en que se pagó el salario.                             | Cualitativa ordinal | Entero no negativo
*experience_level*  | El nivel de experiencia en el trabajo durante el año.     | Cualitativa nominal | Cuatro valores (*EN*, *MI*, *SE*, *EX*)
*employment_type*   | El tipo de empleo para el rol. | Cualitativa nominal | Cuatro valores (*PT*, *FT*, *CT*, *FL*)
*job_title*     | Rol en el que se trabajó durante el año.| Cualitativa nominal | Valores referentes al rol del trabajo
*salary*  | El monto total del salario bruto pagado.| Cuantitativa continua ordinal | Número entero o decimal no negativo  
*salary_currency*   | La moneda del salario pagado como un código de moneda ISO 4217.     | Cualitativa nominal | Valores referentes a tipos de salarios
*salary_in_usd*   | El salario en dólares americanos (USD).                | Cuantitativa continua ordinal | Número entero o decimal no negativo 
*employee_residence*      | País de residencia principal del empleado durante el año laboral como código de país ISO 3166.   | Cualitativa nominal | Valores referentes a países
*remote_ratio* | La cantidad total de trabajo realizado de forma remota.   |  Cualitativa ordinal | Tres valores, 0, 50 y 100
*company_location*    | El país de la oficina principal del empleador o sucursal contratante.  |  Cualitativa nominal | Valores referentes a países
*company_size*  | La mediana del número de personas que trabajaron para la empresa durante el año (Tamaño de la empresa).|  Cualitativa nominal | Tres valores (*S*,*M*,*L*)

### Análisis exploratorio

**Variable año**

```{r}
library(modeest)
mfv(muestra$work_year)

barplot(table(muestra$work_year),main="Gráfico de barras de la variable año",col="darkred",xlab = "Año de trabajo",ylab = "Cantidad de empleados")
```

Del gráfico podemos inferir que a medida que transcurrieron los años del 2020 al 2023 se ha ido en aumento el número de empleados de Data Science por lo que podemos inferir que hubi un constante aumento en la demanda, del 2020 al 2021 la diferencia no es tan notoria, como lo es desde el 2021 al 2022, que se ve un indice alto de diferencia. 


**Variable nivel de experiencia**

  * EN, que se refiere a Entry-level/Junior.
  * MI, que hace referencia a Nivel Medio/Intermedio.
  * SE, que se refiere a Nivel Superior/Experto.
  * EX, que hace referencia a nivel Ejecutivo/Director.
  
```{r}
library(modeest)
mfv(muestra$experience_level)

barplot(table(muestra$experience_level),main="Gráfico de barras de la variable nivel de experiencia",col="darkgreen",xlab = "Nivel de experiencia",ylab = "Cantidad de empleados")
```

Del gráfico se infiere que la mayoría de los empleados tienen un nivel de experiencia Superior/Experto, seguido de el nivel de experiencia Medio Intermedio con un número mucho menor al Superior/ Experto, a ello le sigue el nivel Entry-level/Junior menor al nivel Medio Intermedio y por ultimo tenemos al Nivel Ejecutivo/Superio con un número muy bajo de empleados con ese nivel de experiencia.


**Variable tipo de empleo**

Hay 4 tipos de empleo aquí:

  * PT - A tiempo parcial
  * FT - Tiempo completo
  * CT - Contrato
  * FL - Independiente

```{r}
library(modeest)
mfv(muestra$employment_type)

barplot(table(muestra$employment_type),main="Gráfico de barras de la variable tipo de empleo",col="#CD661D",xlab = "Tipo de empleo",ylab = "Cantidad de empleados")
```

Del grafico se infiere que, todos o la mayoria de empleados trabajan a Tiempo Completo, y en consecuencia muy pocos trabajan A Tiempo Parcial, Contrato e Independiente.


**Variable rol de empleo**

```{r}
library(modeest)
mfv(muestra$job_title)

length(table(muestra$job_title))

frec <- table(muestra$job_title)
frec <- sort(frec, decreasing = TRUE)
top5frecuencias <- head(frec, 5)

barplot(top5frecuencias, 
        main = "Los 5 empleos más frecuentes",
        xlab = "Empleos",
        ylab = "Frecuencia",
        col="#B4EEB4")

```


**Variable salario**

```{r}
library(modeest)
moda1<-mfv(muestra$salary)
m1<- format(moda1, scientific = F)
m1

tam1=length(table(muestra$salary)) #Cantidad de salarios distintos
tam1

salariosFrecuentes <- sort(table(muestra$salary), decreasing = TRUE)[1:15]

boxplot(as.numeric(names(salariosFrecuentes)),
        main = "Boxplot de los 15 salarios más frecuentes",
        horizontal = T,
        xlab = "Salario",
        col = "#CDB79E")

max(muestra$salary) #Salario más alto

summary(muestra$salary)

```

Del gráfico se infiere que hay una tendencia de que los 15 salarios mas frecuentes osclian entre 75000 hasta 107500, siendo el mínimo y el máximo respectivamente. Ademas de ello se ve un un sesgo muy ligero hacia la izquierda.


**Variable tipo de salario**

```{r}
library(modeest)
mfv(muestra$salary_currency)

barplot(table(muestra$salary_currency),main="Gráfico del tipo de salario",col="darkred",xlab = "Cantidad",ylab = "Tipo")
```

Del gráfico podemos inferir que los empleados reciben un tipo de salario USD en gran magnitud, y los otros tipos de salario es muy poco en comparación con el tipo de salario USD, que hace referencia a dólares.


**Variable salario en dólares**

```{r}
library(modeest)
moda2<-mfv(muestra$salary_in_usd)
m2<- format(moda2, scientific = F)
m2

tam2=length(table(muestra$salary_in_usd)) # Cantidad de salarios distintos
tam2

salariosFrecuentes <- sort(table(muestra$salary_in_usd), decreasing = TRUE)[1:15]

boxplot(as.numeric(names(salariosFrecuentes)),
        main = "Boxplot de los 15 salarios en dólares más frecuentes",
        horizontal = T,
        xlab = "Salario en dólares",
        col = "#7AC5CD")

max(data$salary) #Salario más alto

summary(muestra$salary_in_usd)
```

En esta gráfica podemos observar cuanto suele ganar una persona de la carera de ciencia de datos.

**Variable país de residencia del empleado**

```{r}
library(modeest)
mfv(muestra$employee_residence)

fr1 <- table(muestra$employee_residence)
top1 <- names(sort(fr1, decreasing = T))[1:10]
barplot(fr1[top1], main = "Los 10 países más frecuentes", xlab = "Países", ylab = "Cantidad", col="peru")

```

Del grafico se infiere que el país con mas cantidad de empleados residentes de Data Science, es US (ESTADOS UNIDOS), la gran mayoría vive o reside ahí, seguido de los demás países con una cantidad de empleados mucho menor.


**Variable trabajo remoto**

La relación remota consta de 3 valores:

  * 0 : Sin trabajo remoto (menos del 20 %)
  * 50 : Parcialmente remoto
  * 100 : Totalmente remoto (más del 80 %)
  
```{r}
library(modeest)
mfv(muestra$remote_ratio)

barplot(table(muestra$remote_ratio),main="Gráfico de barras de la variable trabajo remoto",col="darkblue",xlab = "Cantidad de trabajo remoto",ylab = "Cantidad de empleados")

```

Del grafico inferimos que los empleados de Data Science que no tienen trabajo remoto es mayor en comparación al numero de los que trabajan de manera Totalmente remota y los que tienen un trabajo Parcialmente remoto es mucho menor. La tendencia indica que la mayoría de los empleados no trabajan de manera remota o no tienen una cantidad considerable de trabajo remoto.


**Variable país del empleo**

```{r}
library(modeest)
mfv(muestra$company_location)

fr2 <- table(muestra$company_location)
top2 <- names(sort(fr2, decreasing = T))[1:10]
barplot(fr2[top2], main = "Los 10 países más frecuentes", xlab = "Países", ylab = "Cantidad", col="orange")
```


**Variable tamaño de la compañía**

Hay que tener 3 consideraciones:

  * S, que se refiere a pequeña empresa (empresas de  hasta 50 empleados)
  * M, que hace referencia a mediana empresa (mas de 50 empleados hasta 100)
  * L, que se refiere a gran empresa (mas de 100)
  
```{r}
library(modeest)
mfv(muestra$company_size)

barplot(table(muestra$company_size),main="Gráfico de barras de la variable tamaño de la compañía",col="brown",xlab = "Tamaño de la compañía",ylab = "Cantidad de empleados")
```

Del gráfico inferimos que hay una gran concentración de empleados trabajando en medianas empresas donde la cantidad de empleados va de 50 a 100 empleados y en los dos tipos de empresas la cantidad de empleados es menor.


# **Análisis descriptivo**

## Salario en dólares - Nivel de experiencia

```{r}

#Gráfico de barras
library(ggplot2)
ggplot(muestra, aes(x = experience_level, y = salary_in_usd)) +  stat_summary(fun = "mean", geom = "bar", fill = "darkblue") + xlab("Nivel de experiencia") + ylab("Salario promedio")

#Análisis del modelo lienal
modelo1 <- lm(salary_in_usd ~ experience_level, data = muestra)
summary(modelo1)

```


## Salario en dólares - País del empleado

```{r}
#Promedio por países
aggregate(salary_in_usd ~ employee_residence, data = muestra, FUN = mean)

library(ggplot2)
ggplot(data = muestra, aes(x = employee_residence, y = salary_in_usd)) +
  stat_summary(fun = mean, geom = "bar", fill="#EEAD0E") +
  coord_flip()

```

## Tamaño de la compañía - Salario en dólares

```{r}

#Salario promedio en dólares dependiendo el tamaño de la compañía
aggregate(salary_in_usd ~ company_size, data = muestra, FUN = mean)

#Modelo de regresión lineal relacionado ambas variables
modelo2 <- lm(salary_in_usd ~ company_size, data = muestra)
summary(modelo2)

```


## País del empleado - Tamaño de la compañía

Como resultado de una relación entre estas dos variables, podemos observar que en ciertos países hay una mayor presencia de medianas y largas empresas, lo cual nos indica que dependiendo del país, existe una mayor solidez y crecimiento de las empresas, con lo cual, se permite un mejor proceso de selección de personal y un mejor desarrollo para lograr objetivos y metas.

```{r}
tablaC <- table(muestra$employee_residence, muestra$company_size)
print(tablaC)

```


## Tipo de empleo - Trabajo remoto

Relacionamos la cantidad de trabajo remoto con respecto a los cuatro tipos de empleo que encontramos: Tiempo Parcial, Tiempo Completo, Con contrato e Independiente.

```{r}

tablaC1 <- table(muestra$employment_type, muestra$remote_ratio)
tablaC1

```


## Rol de empleo - Salario en dólares

```{r}

library(dplyr)
library(ggplot2)

#Salario promedio para cada rol de empleo (especialidad)
salariopromedio <- muestra %>% group_by(job_title) %>% summarise(prom = mean(salary_in_usd))
salariopromedio

#Rango entre el salario máximo y mínimo
rango <- muestra %>% group_by(job_title) %>% summarise(ran = max(salary_in_usd) - min(salary_in_usd))
rango

#Encontramos los 5 empleos mejor remunerados
top5 <- salariopromedio$job_title[1:5]
top5

#Filtramos los 5 empleos mejor pagos con respecto a la muestra
mfil <- muestra %>% filter(job_title %in% top5)

boxplot(mfil$salary_in_usd ~ mfil$job_title, col = '#009ACD',main = "Valoración por tiempo de encuesta" , xlab="Tiempo de encuesta" , ylab = "Valoración")

modelo3=lm(mfil$salary_in_usd ~ mfil$job_title)
summary(modelo3)
```


# **Probabilidad empírica**

Determinamos el espacio de resultados teórico y la función de probabilidad para los eventos atómicos de manera empírica para dos variables interesantes de nuestro trabajo.

En este caso, elegimos las variables:

- Año (Cantidad de empleados de Data Science que empezaron a trabajar en un determinado año)
- Nivel de experiencia 

Trabajamos, primero, con la variable año:

1. Calculamos cuántos valores distintos hay en la base de datos, de esa forma hallaremos el espacio muestral (o también llamado espacio de resultados)

```{r}
muestra

```

```{r}
#Trabajamos con la variable año
#muestra$año

unique(muestra$work_year) # Años únicos en la muestra
frecuencia1=table(muestra$work_year)
frecuencia1
```


2. Definimos los eventos:

  - El evento atómico asociado al año 2020 sería: 
  f1 = "Seleccionar una persona que comenzó a trabajar en 2020 en una muestra de tamaño 1000"
  
  - El evento atómico asociado al año 2021 sería: 
  f2 = "Seleccionar una persona que comenzó a trabajar en 2021 en una muestra de tamaño 1000"
  
  - El evento atómico asociado al año 2022 sería: 
  f3 = "Seleccionar una persona que comenzó a trabajar en 2022 en una muestra de tamaño 1000"
  
  - El evento atómico asociado al año 2023 sería: 
  f4 = "Seleccionar una persona que comenzó a trabajar en 2023 en una muestra de tamaño 1000"


3. Calcular la función de probabilidad para los eventos atómicos del punto 1

- Probabilidad del año 2020: 
  
```{r}
f1=frecuencia1["2020"]/1000
f1
```
  
- Probabilidad del año 2021: 
  
```{r}
f2=frecuencia1["2021"]/1000
f2
```
  
  
- Probabilidad del año 2022: 
  
```{r}
f3=frecuencia1["2022"]/1000
f3
```

  
- Probabilidad del año 2023: 
  
```{r}
f4=frecuencia1["2023"]/1000
f4
```

Realizamos la suma para comprobar que el resultado de las probabilidades es 1

```{r}

sum(f1,f2,f3,f4)

```


Finalmente trabajamos con la variable nivel de experiencia:

1. Calculamos cuántos valores distintos hay en la base de datos, de esa forma hallaremos el espacio muestral (o también llamado espacio de resultados)

```{r}
#muestra$salario_dolares

length(unique(muestra$experience_level)) # Años únicos en la muestra
 
frecuencia2=table(muestra$experience_level)
frecuencia2

```


2. Definimos los eventos: 


  - El evento atómico asociado al nivel EN sería: 
  g1 = "Seleccionar una persona de nivel EN en una muestra de tamaño 1000"
  
  - El evento atómico asociado al nivel EX sería: 
  g2 = "Seleccionar una persona de nivel EX en una muestra de tamaño 1000"
  
  - El evento atómico asociado al nivel MI sería: 
  g3 = "Seleccionar una persona de nivel MI en una muestra de tamaño 1000"
  
  - El evento atómico asociado al nivel SE sería: 
  g4 = "Seleccionar una persona de nivel SE en una muestra de tamaño 1000"


Hay que tomar en cuenta las aclaraciones con respecto al nivel de experiencia:

  * EN, que se refiere a Entry-level/Junior.
  * MI, que hace referencia a Nivel Medio/Intermedio.
  * SE, que se refiere a Nivel Superior/Experto.
  * EX, que hace referencia a nivel Ejecutivo/Director.
  

3. Calcular la función de probabilidad para los eventos atómicos del punto 1

- Probabilidad del nivel EN: 
  
```{r}
g1=frecuencia2["EN"]/1000
g1
```
  
- Probabilidad del nivel EX: 
  
```{r}
g2=frecuencia2["EX"]/1000
g2
```
  
  
- Probabilidad del nivel MI: 
  
```{r}
g3=frecuencia2["MI"]/1000
g3
```

  
- Probabilidad del nivel SE: 
  
```{r}
g4=frecuencia2["SE"]/1000
g4
```


Realizamos la suma para comprobar que el resultado de las probabilidades es 1

```{r}
sum(g1,g2,g3,g4)
```


# **Probabilidad condicional**

```{r}
library(readr)
library(dplyr)
library(sampling)
```

```{r}
data<- read.csv('salarios_data_science.csv')
colnames(data)<-c('año','nivel_experiencia','tipo_empleo',
                  'titulo_profesional','salario','moneda_salario','salario_dolares',
                  'residencia_empleados','relacion_remota',
                  'localizacion_empresa','tamaño_empresa')
```

## Muestra y variables seleccionadas

Seleccionamos un muestra de tamaño n=100 utilizando una semilla para poder trabajar con la misma muestra cada que se ejecute el codigo

```{r}
set.seed(20)
muestra<-slice_sample(.data=data,n = 100,replace = F)

```


Para esta actividad trabajare con dos variables, las variables que utilizaremos:

- Variable 1: Salario en dolares

- Variable 2: Tamaño de empresa

```{r}
muestra2<-muestra %>%
  select(salario_dolares,tamaño_empresa)
head(muestra2,6)
```


## Eventos Dependientes

Definimos los eventos:

A:Seleccionar un empleado de Data Science cuyo salario es >= de 15000 dolares.

B:Seleccionar una empresa de tamaño mediano.

Demostraremos que esos eventos son eventos dependientes:

P(A) = Probabilidad de seleccionar un empleado de data science cuyo salario >=15000 dolares

```{r}
total<-dim(muestra2)[1]
c_eA<-muestra2 %>%
  filter(salario_dolares >=150000) %>%
  summarise(conteo=n())
c_eA
p_A=c_eA[[1]]/total
p_A # la Probabilidad del evento A es de 0.37

```


P(B) = Probabilidad de seleccionar una empresa de tamaño mediano

```{r}
c_eB<-muestra2 %>%
  filter(tamaño_empresa =='M') %>%
  summarise(conteo=n())
c_eB
p_B=c_eB[[1]]/total
p_B # la probabilidad del evento B es de 0.84
```


P(A y B) = Probabilidad de selecionar un data science con un sueldo >=150000 y que  trabaja en una empresa de tamaño = M

```{r}
numero_A_y_B<-muestra2 %>%
  filter(salario_dolares >=150000 & tamaño_empresa =='M') %>%
  summarise(conteo=n())
numero_A_y_B
p_A_y_B=numero_A_y_B[[1]]/total
p_A_y_B
```

Verificamos si P(AyB) = P(A)P(B)

```{r}
p_A_y_B==p_A*p_B
```


Como podemos ver no se cumple la premisa anterior lo que indica que los eventos A y B son dependientes

Por otro lado podemos caracterizar la P(A) por la probabilidad total hallamos:

P(complemento de B) = 1-p(B)

```{r}
1- p_B
```


P(A dado B) =

```{r}
p_A_dado_B=numero_A_y_B[[1]]/c_eB[[1]]
p_A_dado_B
```


P(A dado CB) = P(evento A dado el complemento del evento B)

```{r}
#P(A y CB)
numero_A_y_CB<-muestra2 %>%
  filter(salario_dolares >=150000 & tamaño_empresa !='M') %>%
  summarise(conteo=n())
numero_A_y_CB
p_A_y_CB=numero_A_y_CB[[1]]/total
p_A_y_CB
```


```{r}
# P(CB)
c_CB<-muestra2 %>%
  filter(tamaño_empresa !='M') %>%
  summarise(conteo=n())
c_CB
p_CB=c_CB[[1]]/total
p_CB
```


```{r}

#P(A dado el complento de B)
p_A_dado_CB=numero_A_y_CB/c_CB
p_A_dado_CB
```


## Eventos Independientes

```{r}
muestra3<-muestra %>%
  select(tipo_empleo,año)
View(head(muestra3,6))
```


Definimos los eventos:

D: Seleccionar un data science cuyo Tipo de empleo sea 'FL'.

B: Que el pago se diera en el año 2023.

```{r}
total<-dim(muestra3)[1]
numero_D<-muestra3 %>%
  filter(tipo_empleo=='FL') %>%
  summarise(conteo=n())
numero_D
proba_D=numero_D[[1]]/total
proba_D 
```


P(c) = Probabilidad de que el pago se diera en 2023

```{r}
numero_c<-muestra3 %>%
  filter(año==2023) %>%
  summarise(conteo=n())
numero_c
p_c=numero_c[[1]]/total
p_c 
```


P(D y C) = Probabilidad de selecionar un data science que tenga un tipo de empleo igual a 'FL' y que recibiera el pago el 2023

```{r}
numero_D_y_C<-muestra3 %>%
  filter(tipo_empleo=='FL' & año=="2023") %>%
  summarise(conteo=n())
numero_D_y_C
p_D_y_C=numero_D_y_C[[1]]/total
p_D_y_C
```


Verificamos si P(DyC) = P(D)P(C)

```{r}
p_D_y_C==proba_D*p_c
```


Como podemos ver se cumple la premisa anterior lo que indica que los eventos Cy D son independientes


# **Variables Discretas y Continuas**

```{r}
library(ggplot2)
library(readr)
library(dplyr)
library(sampling)
library(car)

```
 
```{r}
data<- read.csv('salarios_data_science.csv')
colnames(data)<-c('año','nivel_experiencia','tipo_empleo',
                  'titulo_profesional','salario','moneda_salario','salario_dolares',
                  'residencia_empleados','relacion_remota',
                  'localizacion_empresa','tamaño_empresa')

## seleccionamos una muestra de tamaño 400
set.seed(20)
data1<-slice_sample(.data=data,n = 400,replace = F)
head(data1,3)
```


## Variables aleatorias Discretas

Recodificamos la variable Trabajo remoto que tenia 3 categorias a 2 categorias creando una nueva variable condición de trabajo

0 == Que no estaba en trabajo remoto

1 == Que si esta trabajando en remoto

```{r}
data1$condicion_trabajo[data1$relacion_remota== '50'|data1$relacion_remota=='100']<-1
data1$condicion_trabajo[data1$relacion_remota=='0']<-0
data1 %>%
  count(condicion_trabajo,sort=F)
head(data1,6)
```


### Distribucion Binomial

Numero de existo en n ensayos.

Parámetros:

p = Probabilidad de éxito

n = Tamaño de la muestra

X = # de empleados de Data Science que estan con trabajo remoto entre los años 2022-2023 

$$X∼b(n,p)$$

Para nuestro ejemplo la probabilidad de éxito es:

p = Probabilidad que un empleado de data sciencie este en trabajo remoto entre los años 2022-2023

El tamaño de muestra es:

n = 100

```{r}
N<-400
conteo=data1%>%
  filter(condicion_trabajo=='1')%>%
  summarise(conteo=n())
p=as.numeric(conteo/N)
p
```

n = Tamaño de la muestra

```{r}
n<-100
```


### Funcion de Probabilidad

Es una función que devuelve la probabilidad de que una variable aleatoria discreta sea exactamente igual a algún valor. 

Es una función que asocia a cada punto de su espacio muestral X la probabilidad de que esta lo asuma.

Nuestra variable X tiene distribución binomial con los siguientes parámetros:

$$X∼B(100,0.465)$$

Graficamos la función de probabilidad de nuestra variable X

```{r}
n=100
x<-1:100
plot(dbinom(x, size =100, prob = 0.465), type = "h", lwd = 1,col='blue',
     main = "Función de probabilidad binomial",
     ylab = "P(X = x)", xlab = "Número de éxitos")

```

### Propiedades 

$$E(X)= np, \qquad V(X)= np(1-p)$$

```{r}
esperanza_X=n*p
esperanza_X

```
```{r}
varianza_X=n*p*(1-p)
varianza_X

```

**Ejemplo**

Se sabe que el 46.5% de empleados de Data Science tiene trabajo remoto,se selecciona una muestra de al azar de 100. 
¿Cual es la probabilidad de que el numero de Data Science que tienen trabajo remoto en la muestra no exceda 45? 

$$P(X<=45)$$

```{r}
pbinom(45,size = 100,prob = 0.462)
```
```{r}
#para graficar el ejemplo anterior
binom_sum <- function(size, prob, lb, ub, col = 4, lwd = 1, ...) {
    x <- 0:size
    
    if (missing(lb)) {
       lb <- min(x)
    }
    if (missing(ub)) {
        ub <- max(x)
    }
      
    plot(dbinom(x, size = size, prob = prob), type = "h", lwd = lwd, ...)
  
    if(lb == min(x) & ub == max(x)) {
        color <- col
    } else {
        color <- rep(1, length(x))
        color[(lb + 1):ub ] <- col
    }
    
    lines(dbinom(x, size = size, prob = prob), type = "h",
          col =  color,lwd = lwd, ...)
}

```
```{r}
binom_sum(size = 100, prob = 0.465, ub = 45, lwd = 2,
          ylab = "P(X <= x)", xlab = "Número de éxitos")
```

$$Distribucion\qquad Binomial\qquad Negativa$$

Numero de veces que se repite el ensayo hasta obtener r éxitos

Los parámetros son:

p = Probabilidad de éxito

r = Cantidad de éxitos

## Variable aleatoria

Y = Numero de empleados seleccionados hasta que 4 de ellos estén con trabajo remoto entre los años 2022-2023 

$$Y∼Bn(p,r)$$

```{r}
n=100
r<-4
y<-1:100
plot(y,dnbinom(y, size =4, prob = 0.465), type = "h", lwd = 1, col='blue',
     main = "Función de probabilidad binomial Negativa",
     ylab = "P(Y = y)", xlab = "Número de éxitos")

```


### Propiedades

$$E(Y)= r/p, \qquad V(Y)= r(1-p)/p^2$$

```{r}
esperanza_y=r/p
esperanza_y

```
```{r}
varianza_y=r*(1-p)/p^2
varianza_y
```


**Ejemplo**

Se sabe que el 46.5% empleados de Data Science tiene trabajo remoto,se selecciona una muestra de al azar de 100. 
¿Cual es la probabilidad de seleccionar al menos 20 empleados de Data Science, antes de que para encontrar 4 de ellos que estén en trabajo remoto

$$P(Y>=20)=1-P(Y<20)=P(Y=0)+...+P(Y=19) $$

```{r}
1-pnbinom(19,size =4,prob = 0.462)
```


## Variables aleatorias Continuas

```{r}
data2<-data1%>%
  select(salario_dolares)
```


### Distribución Normal

Z = Salario en dolares de empleados de Data Science entre los años 2022-2023 

```{r}
mu=mean(data1$salario_dolares)
densidad<-density(data1$salario_dolares)
plot(densidad,lwd=2,col='red',main = 'Densidad')+
abline(v = mu)
```

La recta vertical al grafico de densidad marca la media  y notamos que no divide en partes iguales a la grafica,lo que nos da indicios de que nuestra variable no cumple con la normalidad.


### Promedio

```{r}
promedio<-mean(data1$salario_dolares)
promedio
```

### Mediana

```{r}
mediana<-median(data1$salario_dolares)
mediana
```

### Varianza Muestra

```{r}
varianza_z<-var(data1$salario_dolares)
varianza_z
```

### Varianza Población

```{r}
vari<-var(data$salario_dolares)
vari
```

Se observa que la media y mediana no coinciden en valores ni están próximos. La varianza muestral no es igual a varianza poblacional (base de datos)

```{r}
qqPlot(data$salario_dolares,pch=20)
```

Los valores están fuera de las bandas de confianza del grafico qqplot. Concluimos que la variable aleatoria no tiene de una distribución normal .

**CASO: Suponiendo que la muestra tenga de una distribución normal**

**Ejemplo:**

Los salarios empleados de Data Science se distribuyen segun una distribución normal de media 140810.6 y varianza de 4628059267

Calcular el porcentaje de empleados de Data Science que cobran mas 180000 dolares

Calcular el porcentaje de empleados de Data Science que cobran menos de 600000

Suponiendo..

$$P(Z>180000)=1-P(Z<=180000)$$

$$Z∼N(u,sigma^2)$$

```{r}
1-pnorm(180000,mean = promedio,sd=sqrt(varianza_z))
```

El porcentaje de empleados de Data Science que cobran mas de 180000 dolares es de 28,2%

$$P(Z<60000)$$

```{r}
pnorm(60000,promedio,sqrt(varianza_z))
```

El porcentaje de empleados de Data Science que cobran menos de 60000 dolares es de 11.7%


# **Conclusiones**

*
Tras analizar los datos y examinar la evolución de la demanda de la carrera de ciencia de datos entre los años 2020 y 2023, se pudo observar un crecimiento significativo en la demanda de profesionales en este campo. Este crecimiento se tradujo en un incremento en los salarios de los especialistas en ciencia de datos a nivel internacional durante ese período. Estos hallazgos respaldan la idea de que la ciencia de datos continúa siendo un campo altamente demandado y en constante expansión, con una creciente necesidad en diversas industrias para analizar grandes volúmenes de datos y extraer información valiosa para la toma de decisiones. Esta tendencia positiva en la demanda de profesionales en ciencia de datos sugiere oportunidades laborales prometedoras para aquellos que buscan ingresar o progresar en esta carrera en los próximos años.

*
Al analizar los datos recopilados y las gráficas obtenidas, se pudo concluir que Estados Unidos es el país donde la industria de la ciencia de datos está más desarrollada y tiene una mayor demanda. Esta conclusión se respalda por la diferencia significativa en los salarios de Data Science en comparación con otros países. Los profesionales en Estados Unidos reciben salarios más elevados para diferentes puestos en la carrera de ciencia de datos. Esta disparidad salarial se puede justificar por la concentración de empresas tecnológicas y la presencia de un ecosistema sólido en el campo de la ciencia de datos en dicho país. No obstante, es importante destacar que existen variaciones salariales considerables dentro de Estados Unidos, dependiendo de la ubicación geográfica y otros factores económicos y laborales.

* 
Luego de nuestro análisis relacionando las variables *nivel de experiencia* y *rol de empleo* con la variable *salario en dólares*, podemos observar que, efectivamente, los empleados con una mejor experiencia son los que reciben un mejor salario, pero además, los empleados con más especialidad en ciertos sectores de Data Science son también mejor remunerados. Este es el caso por ejemplo de un **AI Developer**, un desarrollador de Inteligencia Artificial, que podemos afirmar que se encuentra dentro del top 5 de los roles mejor pagados. Esto se da debido a las necesidades del mundo actual, más profundamente en el sector de Data Science. En pocas palabras, a mayor experiencia se presenta un mayor salario (en la mayoría de casos).
